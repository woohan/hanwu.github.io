---
layout: archive
title: "Research"
permalink: /research/
author_profile: true
---

My research interests encompass three major domains, each presenting a wide range of advanced possibilities. In the realm of **Dependable and Secure Machine Learning**, I explore pivotal concepts including Federated Learning, Inference Attacks, Differential Privacy, and the interesting frontier of Machine Unlearning. Additionally, my expertise extends to **Distributed Data Synthesis**, involving the development of Tabular Data Synthesis Models, the nuanced practice of Distributed Learning using Tabular GANs, and the rigorous evaluation of Synthetic Data. Beyond these pursuits, I'm strongly dedicated to propelling application-oriented and **Interdisciplinary Research** initiatives associated with privacy and security in AI applications. This dedication is rooted in my extensive involvement in collaborative projects that bring together experts from diverse backgrounds, fostering a comprehensive approach to intricate challenges.

In the coming 3 to 5 years, my research agenda will encompass, but not be restricted to, the following areas:
- **Machine Unlearning for AI applications based on tabular data.**
    - *Machine Unlearning is a novel privacy-preserving technology. More details [here](https://doi.org/10.1145/3603620){:target="_blank"}.*
- **Machine Unlearning for Federated Learning systems.**
    - *Lots of research challenges in applying Machine Unlearning to FL. More details [here](https://dl.acm.org/doi/10.5555/3618408.3618577){:target="_blank"}. I am presently collaborating with a team of researchers at the University of Birmingham on this subject.*
- **Privacy attacks in Machine/Federated Learning.**
    - *The more we understand the attacker, the stronger we forge our defenses. Studying privacy attacks on ML/FL applications is important for trusts in AI technologies. More details [here](https://ieeexplore.ieee.org/document/10274102){:target="_blank"}.*
- **Federated Learning for Smart Home applications.**
    - *Applying FL to time-series data presents significant challenges. Also exploring the definition of privacy within time-series data is crucial. A reference paper is [here](https://ieeexplore.ieee.org/document/9415623){:target="_blank"}.*
- **Adversarial attacks against Large Language Models.**
    - *As the most revolutionary AI technology to emerge in recent years, LLMs encounter significant challenges related to security and privacy. This [blog](https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/){:target="_blank"} from OpenAI helps you to understand it.*

Projects
=====

- UnFed: Selective Forgetting in Federated Financial Applications (£ 20,000)
    - *EPSRC funded (UKFin programme)*
    - *April 2024 - Present*
    - *Position: Co-Investigator*
- AGENCY: Assuring Citizen Agency in a world with Complex Online Harms (£ 2,674,250)
    - *EPSRC funded*
    - *Jan 2023 - Present*
    - *Position: PostDoc Researcher*
- Tabular Data under Machine Unlearning: Exploring the Public Perception of Privacy (£ 2,970)
    - *The Paul & Yuanbi Ramsay Research Fund funded*
    - *May 2023 - Aug 2023*
    - *Position: Principal Investigator*
- FinTrust: Trust Engineering for the Financial Industry (£ 1,047,202)
    - *EPSRC funded*
    - *May 2021 - Dec 2022*
    - *Position: PostDoc Researcher*
- Collaborative and Privacy-Preserving Deep Learning Technology in Financial Services (£ 2,000)
    - *Alan Turing Institute funded*
    - *July 2022 - Dec 2022*
    - *Position: Principal Investigator*

